## creating a kubernetes cluster
## providing different packages on multiple instances on initial run

- hosts: localhost
  vars:
    subnet:                           
    zone:                            
    vpc:                            
    session: orchestrating_kubernetes_cluster
    worker_count: 2                                             
    master_count: 1
    key: Ansible                
    instance: t2.small
    image: ami-dd3c0f36                                         # CentOS7
    region: eu-central-1                                        # Frankfurt/Main
    worker_tags:
      Name: kube-worker
      Application: Kubernetes
      Service: kubeworker
      Environment: Dev
      Finance-ID: 1337
    master_tags:
      Name: kube-master
      Application: Kubernetes
      Service: kubemaster
      Environment: Dev
      Finance-ID: 1337
    securitygroups: ['SSH']                                     # multiple groups seperatet by comma e.g. ['a','b']

  gather_facts: False
  tasks:

########################################################################################
#   Start generating worker-nodes, wait for SSH, tag them like kube-worker-01,02 etc.  #
#   and add them to the ansible-playbook in-memory inventory                           #
########################################################################################

    - name: "create '{{ worker_count }}' worker nodes"
      local_action:
        module: ec2
        key_name: "{{ key }}"
        group: "{{ securitygroups }}"
        instance_type: "{{ instance }}"
        image: "{{ image }}"
        wait: true
        region: "{{ region }}"
        instance_tags: "{{ worker_tags }}"
        count_tag:
            Service: "{{ worker_tags.Service }}"
        exact_count: "{{ worker_count }}"
        volumes:
          - device_name: /dev/sda1
            volume_type: gp2
            volume_size: 10
            delete_on_termination: true
        vpc_subnet_id: "{{ subnet }}"
        zone: "{{ zone }}"
      register: workers

    - name: "Wait for '{{ worker_count }}' worker nodes SSH to come up"
      local_action: wait_for
                    host={{ item.public_ip }}
                    port=22
                    state=started
      with_items: "{{ workers.instances }}"


    - name: "tagging {{ worker_tags.Name }}'s"
      ec2_tag:
       region: "{{ region }}"
       resource: "{{ item.1.id }}"
       tags:
         Name: "{{ worker_tags.Name }}-{{ '%02d' | format(item.0 + 1) }}"
      with_indexed_items: "{{ workers.instances }}"
      loop_control:
         label: "{{ item.1.id }} - {{ worker_tags.Name }}-{{ '%02d' | format(item.0 + 1) }}"

#######################################################
#  Worker-nodes are up, tagged and have been added to #
#  the ansible-playbook in-memory inventory           #
#######################################################


########################################################################################
#   Start generating master-nodes, wait for SSH, tag them like kube-master-01,02 etc.  #
#   and add them to the ansible in-memory inventory                                    #
########################################################################################

    - name: "create '{{ master_count }}' master nodes"
      local_action:
        module: ec2
        key_name: "{{ key }}"
        group: "{{ securitygroups }}"
        instance_type: "{{ instance }}"
        image: "{{ image }}"
        wait: true
        region: "{{ region }}"
        instance_tags: "{{ master_tags }}"
        count_tag:
            Service: "{{ master_tags.Service }}"
        exact_count: "{{ master_count }}"
        volumes:
          - device_name: /dev/sda1
            volume_type: gp2
            volume_size: 10
            delete_on_termination: true
        vpc_subnet_id: "{{ subnet }}"
        zone: "{{ zone }}"
      register: masters


    - name: "tagging {{ master_tags.Name }}'s"
      ec2_tag:
       region: "{{ region }}"
       resource: "{{ item.1.id }}"
       tags:
         Name: "{{ master_tags.Name }}-{{ '%02d' | format(item.0 + 1) }}"
      with_indexed_items: "{{ masters.instances }}"
      loop_control:
         label: "{{ item.1.id }} - {{ master_tags.Name }}-{{ '%02d' | format(item.0 + 1) }}"


    - name: "Wait for '{{ master_count }}' master nodes SSH to come up"
      local_action: wait_for
                    host={{ item.public_ip }}
                    port=22
                    state=started
      with_items: "{{ masters.instances }}"

    - meta: refresh_inventory

#######################################################
#  Master-nodes are up, tagged and have been added to #
#  the ansible-playbook in-memory inventory           #
#######################################################

#  Deploy some Stuff to _all_ instances in this cluster. eg. users, vim etc.

- hosts: "tag_Application_Kubernetes:&tag_Environment_Dev"
  gather_facts: no

  roles:
    - { role: common/etc-hosts }
    - { role: technology/vim-enhanced }
    - { role: technology/htop }
    - { role: technology/docker }
    - { role: technology/kubernetes-worker }


# Deploy worker-nodes
- hosts: "tag_Application_Kubernetes:&tag_Service_Kubeworker"
  gather_facts: no

  roles:
    - { role: technology/kubernetes-worker }


# Deploy some Stuff to Kube-Master

- hosts: "tag_Application_Kubernetes:&tag_Service_Kubemaster"
  gather_facts: no

  roles:
    - { role: technology/kubernetes-master }
